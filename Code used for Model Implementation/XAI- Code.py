# -*- coding: utf-8 -*-
"""Another copy of Shoe-classify- DEIi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CABQ0SFEnLwOpuKn-HM36xgN3x5FEreI
"""

# Define transformations
from torchvision import transforms
from PIL import Image
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    # Add other transformations as needed
])

# Create dataset instances
#train_dataset = YOLODataset(image_dir='/kaggle/input/shoe-data/train-def/train-def/images', label_dir='/kaggle/input/shoe-data/train-def/train-def/labels', transform=transform)
#val_dataset = YOLODataset(image_dir='/kaggle/input/shoe-data/test/test-def/images', label_dir='/kaggle/input/shoe-data/test/test-def/labels', transform=transform)
train_dataset = YOLODataset(image_dir='/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/Data-defect/train-def/images', label_dir='/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/Data-defect/train-def/labels', transform=transform)
val_dataset = YOLODataset(image_dir='/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/Data-defect/test-def/images', label_dir='/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/Data-defect/test-def/labels', transform=transform)

# Create DataLoader instances
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)

from torch.utils.data import ConcatDataset

# Create DataLoader instances
combined_dataset = ConcatDataset([train_dataset, val_dataset])

import torch
from torch.utils.data import random_split

dataset_size = len(combined_dataset)
train_size = int(0.8 * dataset_size)
val_size = int(0.1 * dataset_size)
test_size = dataset_size - train_size - val_size
print(train_size)
print(val_size)
print(test_size)

train_dataset, val_dataset, test_dataset = random_split(combined_dataset, [train_size, val_size, test_size])

from torch.utils.data import DataLoader

batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print(f"Number of samples in dataset: {len(train_dataset)}")
print(f"Number of samples in dataset: {len(test_dataset)}")
print(f"Number of samples in dataset: {len(val_dataset)}")

import torch
from torchvision.models import efficientnet_b1
import torch.nn as nn

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load the model architecture
model_b1 = efficientnet_b1(pretrained=True)
num_features = model_b1.classifier[1].in_features
model_b1.classifier = nn.Sequential(
    nn.Linear(num_features, 256),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(256, 6)  # 2 for class scores + 4 for bounding box coordinates
)
# Load trained weights
model_b1.load_state_dict(torch.load("/content/model_state_b1.pth", map_location=device))

# Send model to device
model_b1.to(device)

# Set to evaluation mode
model_b1.eval()

# Select last convolutional layer for Grad-CAM
target_layer = model_b1.features[-1]

# Load an image (test sample)
image_path = "/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/Data-defect/test-def/images/aug_502_A-4.jpg"
image = Image.open(image_path).convert("RGB")
image = image.resize((224, 224))  # Resize image to match model input

# Run Grad-CAM with trained model
visualize_gradcam(model_b1, image, target_layer)

# Load an image (test sample)
image_path = "/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/test/images/aug_491_20211201_094229.jpg"
image = Image.open(image_path).convert("RGB")
image = image.resize((224, 224))  # Resize image to match model input

# Run Grad-CAM with trained model
visualize_gradcam(model_b1, image, target_layer)

# Load an image (test sample)
image_path = "/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/test/images/aug_4_20211201_094016.jpg"
image = Image.open(image_path).convert("RGB")
image = image.resize((224, 224))  # Resize image to match model input

# Run Grad-CAM with trained model
visualize_gradcam(model_b1, image, target_layer)

# Load an image (test sample)
image_path = "/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/test/images/aug_458_20211110_185302.jpg"
image = Image.open(image_path).convert("RGB")
image = image.resize((224, 224))  # Resize image to match model input

# Run Grad-CAM with trained model   /content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/test/images/aug_4_20211201_094016.jpg
visualize_gradcam(model_b1, image, target_layer)

# Load an image (test sample)
image_path = "/content/drive/MyDrive/Data_Shoes/newyolo/outputimgs/Data-defect/test-def/images/aug_890_A2.jpg"
image = Image.open(image_path).convert("RGB")
image = image.resize((224, 224))  # Resize image to match model input

# Run Grad-CAM with trained model
visualize_gradcam(model_b1, image, target_layer)

import torch
from torchvision.models import efficientnet_b0
import torch.nn as nn

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


model_b0 = efficientnet_b0(pretrained=True)
num_features = model_b0.classifier[1].in_features
model_b0.classifier = nn.Sequential(
    nn.Linear(num_features, 256),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(256, 6)  # 2 for class scores + 4 for bounding box coordinates
)

# Load trained weights
model_b0.load_state_dict(torch.load("/content/model_stateb0.pth", map_location=device))

# Send model to device
model_b0.to(device)

# Set to evaluation mode
model_b0.eval()

# Select last convolutional layer for Grad-CAM
target_layer = model_b0.features[-1]